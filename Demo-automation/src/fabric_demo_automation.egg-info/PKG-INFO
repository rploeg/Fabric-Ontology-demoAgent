Metadata-Version: 2.4
Name: fabric-demo-automation
Version: 0.1.0
Summary: Automated Fabric Ontology Demo Setup Tool
Author: Azure Ontology Team
License: MIT
Project-URL: Homepage, https://github.com/falloutxAY/rdf-dtdl-fabric-ontology-converter
Project-URL: Bug Tracker, https://github.com/falloutxAY/rdf-dtdl-fabric-ontology-converter/issues
Keywords: fabric,ontology,demo,automation,microsoft
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: azure-identity>=1.15.0
Requires-Dist: azure-storage-file-datalake>=12.14.0
Requires-Dist: requests>=2.31.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: tqdm>=4.66.0
Requires-Dist: tenacity>=8.2.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: rich>=13.7.0
Requires-Dist: rdflib>=7.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.1.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.7.0; extra == "dev"

# Fabric Demo Automation

Automated setup tool for Microsoft Fabric Ontology demos. This CLI tool orchestrates the complete demo setup process with **11 sequential steps**, each independently executable with built-in resume capability.

## Quick Start

```bash
# 1. Install the tool
cd Demo-automation
pip install -e .

# 2. Configure your workspace (one-time setup)
fabric-demo config init

# 3. Validate and setup a demo
fabric-demo validate ../CreditFraud
fabric-demo setup ../CreditFraud

# 4. When done, cleanup
fabric-demo cleanup ../CreditFraud
```

## Configuration

The tool supports multiple configuration sources (in order of precedence):

1. **CLI arguments**: `--workspace-id abc123`
2. **Environment variables**: `FABRIC_WORKSPACE_ID`
3. **Global config file**: `~/.fabric-demo/config.yaml`
4. **Demo-specific config**: `demo.yaml` in demo folder

### First-Time Setup

```bash
# Interactive configuration wizard
fabric-demo config init

# View current configuration
fabric-demo config show

# Show config file location
fabric-demo config path
```

### Environment Variables

Create a `.env` file (see `.env.example`):

```bash
FABRIC_WORKSPACE_ID=your-workspace-id-guid
AZURE_TENANT_ID=your-tenant-id        # Optional
```

## Setup Workflow

The tool executes the following steps in order:

| Step | Description | Validation |
|------|-------------|------------|
| 1. **Validate** | Verify demo folder structure matches spec | ✓ Structure & files |
| 2. **Create Lakehouse** | Create Lakehouse in Fabric workspace | ✓ Resource exists |
| 3. **Upload Files** | Upload `data/lakehouse/*.csv` files to Lakehouse | ✓ Files uploaded |
| 4. **Load Tables** | Convert CSV files to managed Delta tables | ✓ Tables created |
| 5. **Create Eventhouse** | Create Eventhouse with KQL Database | ✓ Resource exists |
| 6. **Ingest Data** | Upload `data/eventhouse/*.csv` and ingest to KQL tables | ✓ Tables have data |
| 7. **Create Ontology** | Create ontology from TTL file with entities, properties, keys | ✓ Definition uploaded |
| 8. **Bind Static** | Bind lakehouse properties (static/NonTimeSeries) with keyColumn | ✓ Static bindings configured |
| 9. **Bind TimeSeries** | Bind eventhouse properties (timeseries) per bindings.yaml | ✓ Timeseries bindings configured |
| 10. **Bind Relationships** | Bind relationship contextualizations per bindings.yaml | ✓ Relationship bindings configured |
| 11. **Verify Setup** | Comprehensive verification of all resources and bindings in Fabric | ✓ All checks passed |

## Features

- **Global configuration**: One-time setup via `fabric-demo config init`
- **Auto-discovery**: Reads demo structure from folder conventions
- **Structured bindings**: Parses `bindings.yaml` (v3.2+) for machine-readable configuration
- **Validation**: Ensures demo packages match generator constraints and limitations
- **Resume capability**: State persistence via `.setup-state.yaml` for failure recovery
- **Individual step execution**: Run any step independently via `run-step` command
- **Smart skipping**: Automatically skips resources/tables that already exist
- **Safe cleanup**: Only deletes resources tracked in state file; `--force-by-name` for fallback
- **Progress reporting**: Real-time progress with rich terminal output

## Installation

```bash
# Navigate to the Demo-automation folder first
cd Demo-automation

# Install in development mode (creates 'fabric-demo' command)
pip install -e .

# Install with dev dependencies
pip install -e ".[dev]"

# Verify installation
fabric-demo --help
```

### Troubleshooting: "fabric-demo not recognized"

If you get the error `fabric-demo: The term 'fabric-demo' is not recognized`, the Python Scripts folder is not in your PATH.

**Option 1: Add Python Scripts to PATH (Recommended)**

```powershell
# Find where the script was installed (look for the WARNING during pip install)
# Usually: C:\Users\<username>\AppData\Roaming\Python\Python3xx\Scripts

# Add to PATH for current session
$env:PATH += ";$env:APPDATA\Python\Python314\Scripts"

# Or add permanently (run as admin or via System Properties > Environment Variables)
[Environment]::SetEnvironmentVariable("PATH", $env:PATH + ";$env:APPDATA\Python\Python314\Scripts", "User")
```

**Option 2: Run with Full Path**

```powershell
# Windows (adjust Python version as needed)
& "$env:APPDATA\Python\Python314\Scripts\fabric-demo.exe" --help
& "$env:APPDATA\Python\Python314\Scripts\fabric-demo.exe" setup ./PillManufacturing
```

**Option 3: Run as Python Module**

```bash
# From the Demo-automation folder
python -m demo_automation.cli --help
python -m demo_automation.cli validate ../MedicalManufacturing
python -m demo_automation.cli setup ../PillManufacturing --workspace-id <id>
```

## Commands Reference

```bash
# Configuration
fabric-demo config init          # Interactive setup wizard
fabric-demo config show          # Show current configuration
fabric-demo config path          # Show config file location

# Demo Operations
fabric-demo init ./Demo          # Create demo.yaml template
fabric-demo validate ./Demo      # Validate demo package
fabric-demo setup ./Demo         # Run full setup
fabric-demo status ./Demo        # Check setup progress
fabric-demo list                 # List resources in workspace
fabric-demo cleanup ./Demo       # Remove demo resources

# Advanced
fabric-demo setup ./Demo --dry-run           # Preview without changes
fabric-demo setup ./Demo --resume            # Resume from failure
fabric-demo run-step ./Demo --step 8         # Run single step
fabric-demo cleanup ./Demo --force-by-name   # Cleanup without state file
```

## Running Individual Steps

Each step can be executed independently using the `run-step` command:

```bash
# Run a step by number (1-11)
fabric-demo run-step ./MedicalManufacturing --step 2  # Create Lakehouse
fabric-demo run-step ./MedicalManufacturing --step 8  # Bind static properties

# Run a step by name
fabric-demo run-step ./MedicalManufacturing --step create_lakehouse
fabric-demo run-step ./MedicalManufacturing --step bind_static
fabric-demo run-step ./MedicalManufacturing --step verify

# Force re-run of a completed step
fabric-demo run-step ./MedicalManufacturing --step 8 --force
```

**Available steps:**
| # | Name | Description |
|---|------|-------------|
| 1 | `validate` | Validate demo folder structure |
| 2 | `create_lakehouse` | Create Lakehouse resource |
| 3 | `upload_files` | Upload CSV files to Lakehouse |
| 4 | `load_tables` | Load CSV files into Delta tables |
| 5 | `create_eventhouse` | Create Eventhouse resource |
| 6 | `ingest_data` | Upload and ingest eventhouse data |
| 7 | `create_ontology` | Create ontology with entities |
| 8 | `bind_static` | Bind lakehouse properties (static) |
| 9 | `bind_timeseries` | Bind eventhouse properties (timeseries) |
| 10 | `bind_relationships` | Bind relationship contextualizations |
| 11 | `verify` | Verify all resources and bindings |

## Configuration

### Environment Variables

```bash
# Required
FABRIC_WORKSPACE_ID=<your-workspace-guid>

# Optional
AZURE_TENANT_ID=<your-tenant-id>
```

### Demo Configuration (demo.yaml)

```yaml
demo:
  name: MedicalManufacturing
  description: "Medical manufacturing ontology demonstration"

fabric:
  workspace_id: ${FABRIC_WORKSPACE_ID}

options:
  skip_existing: true
  dry_run: false
```

## Demo Package Structure

```
DemoName/
├── demo.yaml                    # Configuration (optional - auto-generated)
├── .demo-metadata.yaml          # Version info (auto-generated)
├── .setup-state.yaml            # Resume state (auto-generated, gitignored)
├── ontology/
│   ├── *.ttl                    # Ontology definition (RDF/Turtle)
│   └── ontology-structure.md    # Human-readable structure docs
├── data/
│   ├── lakehouse/*.csv          # Static data → Delta tables
│   └── eventhouse/*.csv         # Timeseries data → KQL tables
├── bindings/
│   ├── bindings.yaml            # Machine-readable bindings (v3.2+, preferred)
│   ├── lakehouse-binding.md     # Human-readable static binding instructions
│   └── eventhouse-binding.md    # Human-readable timeseries instructions
├── queries/
│   └── demo-questions.md        # Demo GQL queries
└── README.md
```

## Bindings Configuration (v3.2+)

The `bindings/bindings.yaml` file is the **source of truth** for automation:

```yaml
version: "1.0"
generatedBy: "fabric-ontology-demo-v3.2"

lakehouse:
  entities:
    - entity: Product
      sourceTable: DimProduct
      keyColumn: ProductId
      properties:
        - property: ProductId
          column: ProductId
          type: string
        - property: Product_Name
          column: Product_Name
          type: string

  relationships:
    - relationship: produces
      sourceEntity: Facility
      targetEntity: ProductionBatch
      sourceTable: DimProductionBatch
      sourceKeyColumn: FacilityId
      targetKeyColumn: BatchId

eventhouse:
  entities:
    - entity: ProductionBatch
      sourceTable: BatchTelemetry
      keyColumn: BatchId
      timestampColumn: Timestamp
      properties:
        - property: Batch_Temperature
          column: Temperature
          type: double
```

## Constraints Enforced

Based on `fabric-ontology-demo-v2.yaml` and known Fabric limitations:

| Constraint | Enforcement |
|------------|-------------|
| Property types | `string`, `int`, `double`, `boolean`, `datetime` only |
| Entity key types | `string` or `int` only (no datetime/boolean) |
| Property name length | Max 26 characters |
| Static before timeseries | Lakehouse bindings created before Eventhouse |
| OneLake only for static | Uses `LakehouseTable` source type |
| Managed tables only | No shortcuts, views, or external tables |
| **Lakehouse schemas disabled** | Lakehouses must NOT have "Lakehouse schemas (Public Preview)" enabled |
| **sourceSchema: null** | Relationship contextualizations use `null` for lakehouses without schemas |

## Resume & Error Handling

- **On success**: Each step marks completion in `.setup-state.yaml`
- **On failure**: Stops immediately and outputs error; state preserved for resume
- **Resume**: Use `--resume` flag to continue from last successful step
- **Fresh start**: Use `--clear-state` to remove state and start over

## Cleanup Command

The `cleanup` command safely removes only the resources that were created by the setup process:

```bash
# Preview what will be deleted (dry run)
fabric-demo cleanup ./MedicalManufacturing

# Actually delete resources
fabric-demo cleanup ./MedicalManufacturing --confirm
```

**Safety features:**
- **State-based deletion**: Only deletes resources tracked in `.setup-state.yaml` by their IDs
- **No accidental deletion**: Pre-existing resources with matching names are NOT deleted
- **Audit trail**: After cleanup, the state file is preserved with status `cleaned_up`
- **Idempotent**: Running cleanup again shows "No resources recorded" since IDs are cleared

**What gets deleted:**
1. Ontology (deleted first, as it depends on data sources)
2. Eventhouse (includes KQL database)
3. Lakehouse

**What is NOT deleted:**
- The demo folder and its files
- Resources not created by this tool
- The `.setup-state.yaml` file (updated to `cleaned_up` status)

### Troubleshooting: "An error occurred while loading the columns"

If you see this error when viewing relationship bindings in the Fabric UI:

1. **Check Lakehouse schemas**: Ensure the Lakehouse was created WITHOUT "Lakehouse schemas (Public Preview)" enabled
2. **Re-run bindings**: Use `fabric-demo run-step --step bind_relationships --force <demo-path>`
3. **Verify OneLake security**: Ensure OneLake folder-level security is disabled

## Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                    Demo Automation Orchestrator                  │
├─────────────────────────────────────────────────────────────────┤
│  ┌──────────────┐  ┌──────────────┐  ┌────────────────────────┐ │
│  │ StateManager │  │  Validator   │  │   BindingsParser       │ │
│  │ (.yaml)      │  │ (structure)  │  │ (YAML + MD fallback)   │ │
│  └──────────────┘  └──────────────┘  └────────────────────────┘ │
├─────────────────────────────────────────────────────────────────┤
│                        Step Executors                            │
│  ┌─────────────────┐  ┌──────────────────┐  ┌────────────────┐ │
│  │ LakehouseClient │  │ EventhouseClient │  │ FabricClient   │ │
│  │   - Create      │  │   - Create       │  │   - Ontology   │ │
│  │   - Upload CSV  │  │   - KQL Tables   │  │   - Bindings   │ │
│  │   - Load Tables │  │   - Ingest Data  │  │   - Definition │ │
│  └─────────────────┘  └──────────────────┘  └────────────────┘ │
├─────────────────────────────────────────────────────────────────┤
│  ┌──────────────────────────────────────────────────────────┐  │
│  │              OntologyBindingBuilder                       │  │
│  │   - Lakehouse (Static) bindings                          │  │
│  │   - Eventhouse (TimeSeries) bindings                     │  │
│  │   - Relationship contextualizations                       │  │
│  └──────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────┘
```

## License

MIT License
