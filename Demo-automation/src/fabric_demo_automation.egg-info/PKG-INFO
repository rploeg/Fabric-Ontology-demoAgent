Metadata-Version: 2.4
Name: fabric-demo-automation
Version: 0.2.0
Summary: Automated Fabric Ontology Demo Setup Tool
Author: Azure Ontology Team
License: MIT
Project-URL: Homepage, https://github.com/falloutxAY/rdf-dtdl-fabric-ontology-converter
Project-URL: Bug Tracker, https://github.com/falloutxAY/rdf-dtdl-fabric-ontology-converter/issues
Keywords: fabric,ontology,demo,automation,microsoft
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: azure-identity>=1.15.0
Requires-Dist: azure-storage-file-datalake>=12.14.0
Requires-Dist: requests>=2.31.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: tenacity>=8.2.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: rich>=13.7.0
Requires-Dist: rdflib>=7.0.0
Requires-Dist: fabric-ontology-sdk@ git+https://github.com/falloutxAY/Unofficial-Fabric-Ontology-SDK.git@v0.4.0
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.1.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.7.0; extra == "dev"

# Fabric Demo Automation

Automated setup tool for Microsoft Fabric Ontology demos. This CLI tool orchestrates the complete demo setup process with **11 sequential steps**, each independently executable with built-in resume capability.

## Dependencies

This tool uses the [Fabric Ontology SDK](https://github.com/falloutxAY/Fabric-Ontology-SDK) (v0.2.0) for ontology operations including validation, entity/relationship building, and data bindings.

## Quick Start

```bash
# 1. Install the tool
cd Demo-automation
pip install -e .

# 2. Configure your workspace (one-time setup)
python -m demo_automation config init

# 3. Validate and setup a demo
python -m demo_automation validate ../CreditFraud
python -m demo_automation setup ../CreditFraud

# 4. When done, cleanup
python -m demo_automation cleanup ../CreditFraud
```

> ğŸ’¡ **Note**: Use `python -m demo_automation` instead of `fabric-demo` to avoid PATH configuration issues. Both commands are equivalent.

## Configuration

The tool supports multiple configuration sources (in order of precedence):

1. **CLI arguments**: `--workspace-id abc123`
2. **Environment variables**: `FABRIC_WORKSPACE_ID`
3. **Global config file**: `~/.fabric-demo/config.yaml`
4. **Demo-specific config**: `demo.yaml` in demo folder

### First-Time Setup

```bash
# Interactive configuration wizard
python -m demo_automation config init

# View current configuration
python -m demo_automation config show

# Show config file location
python -m demo_automation config path
```

### Environment Variables

Create a `.env` file (see `.env.example`):

```bash
FABRIC_WORKSPACE_ID=your-workspace-id-guid
AZURE_TENANT_ID=your-tenant-id        # Optional
```

## Setup Workflow

The tool executes the following steps in order:

| Step | Description | Validation |
|------|-------------|------------|
| 1. **Validate** | Verify demo folder structure matches spec | âœ“ Structure & files |
| 2. **Create Lakehouse** | Create Lakehouse in Fabric workspace | âœ“ Resource exists |
| 3. **Upload Files** | Upload `data/lakehouse/*.csv` files to Lakehouse | âœ“ Files uploaded |
| 4. **Load Tables** | Convert CSV files to managed Delta tables | âœ“ Tables created |
| 5. **Create Eventhouse** | Create Eventhouse with KQL Database | âœ“ Resource exists |
| 6. **Ingest Data** | Upload `data/eventhouse/*.csv` and ingest to KQL tables | âœ“ Tables have data |
| 7. **Create Ontology** | Create ontology from TTL file with entities, properties, keys | âœ“ Definition uploaded |
| 8. **Bind Static** | Bind lakehouse properties (static/NonTimeSeries) with keyColumn | âœ“ Static bindings configured |
| 9. **Bind TimeSeries** | Bind eventhouse properties (timeseries) per bindings.yaml | âœ“ Timeseries bindings configured |
| 10. **Bind Relationships** | Bind relationship contextualizations per bindings.yaml | âœ“ Relationship bindings configured |
| 11. **Verify Setup** | Comprehensive verification of all resources and bindings in Fabric | âœ“ All checks passed |

## Features

- State-based resume capability
- Individual step execution
- Safe cleanup with audit trail
- Auto-discovery from folder structure
- Rich terminal progress output

## Installation

```bash
cd Demo-automation
pip install -e .
python -m demo_automation --help
```

See [Troubleshooting](../docs/troubleshooting.md) if you get "fabric-demo not recognized" errors.

## Commands

```bash
# Setup
python -m demo_automation config init          # One-time configuration
python -m demo_automation validate ./Demo      # Check demo package
python -m demo_automation setup ./Demo         # Deploy to Fabric
python -m demo_automation status ./Demo        # Check progress
python -m demo_automation cleanup ./Demo       # Remove resources

# Advanced
python -m demo_automation setup ./Demo --resume            # Resume from failure
python -m demo_automation run-step ./Demo --step 8         # Run single step
python -m demo_automation cleanup ./Demo --force-by-name   # Cleanup by name
```

**[ğŸ“– Full CLI Reference â†’](../docs/cli-reference.md)**

## Running Individual Steps

Each step can be executed independently using the `run-step` command:

```bash
# Run a step by number (1-11)
python -m demo_automation run-step ./MedicalManufacturing --step 2  # Create Lakehouse
python -m demo_automation run-step ./MedicalManufacturing --step 8  # Bind static properties

# Run a step by name
python -m demo_automation run-step ./MedicalManufacturing --step create_lakehouse
python -m demo_automation run-step ./MedicalManufacturing --step bind_static
python -m demo_automation run-step ./MedicalManufacturing --step verify

# Force re-run of a completed step
fabric-demo run-step ./MedicalManufacturing --step 8 --force
```

**Available steps:**
| # | Name | Description |
|---|------|-------------|
| 1 | `validate` | Validate demo folder structure |
| 2 | `create_lakehouse` | Create Lakehouse resource |
| 3 | `upload_files` | Upload CSV files to Lakehouse |
| 4 | `load_tables` | Load CSV files into Delta tables |
| 5 | `create_eventhouse` | Create Eventhouse resource |
| 6 | `ingest_data` | Upload and ingest eventhouse data |
| 7 | `create_ontology` | Create ontology with entities |
| 8 | `bind_static` | Bind lakehouse properties (static) |
| 9 | `bind_timeseries` | Bind eventhouse properties (timeseries) |
| 10 | `bind_relationships` | Bind relationship contextualizations |
| 11 | `verify` | Verify all resources and bindings |

## Configuration

### Environment Variables

```bash
# Required
FABRIC_WORKSPACE_ID=<your-workspace-guid>

# Optional
AZURE_TENANT_ID=<your-tenant-id>
```

### Demo Configuration (demo.yaml)

```yaml
demo:
  name: MedicalManufacturing
  description: "Medical manufacturing ontology demonstration"

fabric:
  workspace_id: ${FABRIC_WORKSPACE_ID}

options:
  skip_existing: true
  dry_run: false
```

## Demo Package Structure

```
DemoName/
â”œâ”€â”€ demo.yaml                    # Configuration (optional - auto-generated)
â”œâ”€â”€ .demo-metadata.yaml          # Version info (auto-generated)
â”œâ”€â”€ .setup-state.yaml            # Resume state (auto-generated, gitignored)
â”œâ”€â”€ ontology/
â”‚   â”œâ”€â”€ *.ttl                    # Ontology definition (RDF/Turtle)
â”‚   â””â”€â”€ ontology-structure.md    # Human-readable structure docs
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ lakehouse/*.csv          # Static data â†’ Delta tables
â”‚   â””â”€â”€ eventhouse/*.csv         # Timeseries data â†’ KQL tables
â”œâ”€â”€ bindings/
â”‚   â”œâ”€â”€ bindings.yaml            # Machine-readable bindings (v3.2+, preferred)
â”‚   â”œâ”€â”€ lakehouse-binding.md     # Human-readable static binding instructions
â”‚   â””â”€â”€ eventhouse-binding.md    # Human-readable timeseries instructions
â”œâ”€â”€ queries/
â”‚   â””â”€â”€ demo-questions.md        # Demo GQL queries
â””â”€â”€ README.md
```

## Bindings Configuration (v3.2+)

The `bindings/bindings.yaml` file is the **source of truth** for automation:

```yaml
version: "1.0"
generatedBy: "fabric-ontology-demo-v3.2"

lakehouse:
  entities:
    - entity: Product
      sourceTable: DimProduct
      keyColumn: ProductId
      properties:
        - property: ProductId
          column: ProductId
          type: string
        - property: Product_Name
          column: Product_Name
          type: string

  relationships:
    - relationship: produces
      sourceEntity: Facility
      targetEntity: ProductionBatch
      sourceTable: DimProductionBatch
      sourceKeyColumn: FacilityId
      targetKeyColumn: BatchId

eventhouse:
  entities:
    - entity: ProductionBatch
      sourceTable: BatchTelemetry
      keyColumn: BatchId
      timestampColumn: Timestamp
      properties:
        - property: Batch_Temperature
          column: Temperature
          type: double
```

## Constraints Enforced

Based on `fabric-ontology-demo-v2.yaml` and known Fabric limitations:

| Constraint | Enforcement |
|------------|-------------|
| Property types | `string`, `int`, `double`, `boolean`, `datetime` only |
| Entity key types | `string` or `int` only (no datetime/boolean) |
| Property name length | Max 26 characters |
| Static before timeseries | Lakehouse bindings created before Eventhouse |
| OneLake only for static | Uses `LakehouseTable` source type |
| Managed tables only | No shortcuts, views, or external tables |
| **Lakehouse schemas disabled** | Lakehouses must NOT have "Lakehouse schemas (Public Preview)" enabled |
| **sourceSchema: null** | Relationship contextualizations use `null` for lakehouses without schemas |

## Resume & Error Handling

- **On success**: Each step marks completion in `.setup-state.yaml`
- **On failure**: Stops immediately and outputs error; state preserved for resume
- **Resume**: Use `--resume` flag to continue from last successful step
- **Fresh start**: Use `--clear-state` to remove state and start over

## Cleanup Command

The `cleanup` command safely removes only the resources that were created by the setup process:

```bash
# Preview what will be deleted (dry run)
fabric-demo cleanup ./MedicalManufacturing

# Actually delete resources
fabric-demo cleanup ./MedicalManufacturing --confirm
```

**Safety features:**
- **State-based deletion**: Only deletes resources tracked in `.setup-state.yaml` by their IDs
- **No accidental deletion**: Pre-existing resources with matching names are NOT deleted
- **Audit trail**: After cleanup, the state file is preserved with status `cleaned_up`
- **Idempotent**: Running cleanup again shows "No resources recorded" since IDs are cleared

**What gets deleted:**
1. Ontology (deleted first, as it depends on data sources)
2. Eventhouse (includes KQL database)
3. Lakehouse

**What is NOT deleted:**
- The demo folder and its files
- Resources not created by this tool
- The `.setup-state.yaml` file (updated to `cleaned_up` status)

### Troubleshooting: "An error occurred while loading the columns"

If you see this error when viewing relationship bindings in the Fabric UI:

1. **Check Lakehouse schemas**: Ensure the Lakehouse was created WITHOUT "Lakehouse schemas (Public Preview)" enabled
2. **Re-run bindings**: Use `fabric-demo run-step --step bind_relationships --force <demo-path>`
3. **Verify OneLake security**: Ensure OneLake folder-level security is disabled

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Demo Automation Orchestrator                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ StateManager â”‚  â”‚  Validator   â”‚  â”‚   BindingsParser       â”‚ â”‚
â”‚  â”‚ (.yaml)      â”‚  â”‚ (structure)  â”‚  â”‚ (YAML + MD fallback)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        Step Executors                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LakehouseClient â”‚  â”‚ EventhouseClient â”‚  â”‚ FabricClient   â”‚ â”‚
â”‚  â”‚   - Create      â”‚  â”‚   - Create       â”‚  â”‚   - Ontology   â”‚ â”‚
â”‚  â”‚   - Upload CSV  â”‚  â”‚   - KQL Tables   â”‚  â”‚   - Bindings   â”‚ â”‚
â”‚  â”‚   - Load Tables â”‚  â”‚   - Ingest Data  â”‚  â”‚   - Definition â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              OntologyBindingBuilder                       â”‚  â”‚
â”‚  â”‚   - Lakehouse (Static) bindings                          â”‚  â”‚
â”‚  â”‚   - Eventhouse (TimeSeries) bindings                     â”‚  â”‚
â”‚  â”‚   - Relationship contextualizations                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## License

MIT License
